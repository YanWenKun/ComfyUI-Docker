# 适配国内网络环境的 ComfyUI 容器镜像

image::../docs/chart-concept-cn.zh.svg["布局"]

https://hub.docker.com/r/yanwk/comfyui-boot/tags?name=cu124-cn[在 Docker Hub 上查找该镜像]

image:https://github.com/YanWenKun/ComfyUI-Docker/actions/workflows/build-cu124-cn.yml/badge.svg["GitHub Workflow 执行状态",link="https://github.com/YanWenKun/ComfyUI-Docker/actions/workflows/build-cu124-cn.yml"]

`yanwk/comfyui-boot:cu124-cn` 是专门为国内网络环境考虑的 ComfyUI Docker 镜像，在下载镜像、程序、扩展、模型时使用国内源。


## 工作流程

1. 初次启动时，启动脚本会下载 ComfyUI、ComfyUI-Manager、大量扩展（自定义节点）、单个大模型以及少量功能性模型。
2. 整个 ComfyUI 会保存在本地 (`./storage/ComfyUI`) 。
3. 如果你已经有了现成的 ComfyUI 包，放在上述目录，并新建一个空白文件 (`./storage/.download-complete`)，启动脚本会跳过下载。
4. 使用 ComfyUI-Manager 即可更新组件（在 ComfyUI 页面中找到“Manager”）。Manager 也可下载模型，但可能需要
<<pre-start, 挂代理>>
。


## 运行前提

* NVIDIA 显卡，建议 8GB 以上显存
** 理论上 Maxwell（GTX 900系）之后的显卡架构均支持运行，但能跑多大的模型主要取决于显存。
** 4~6GB 显存可以跑 SD 1.5 模型，再小需要改启动参数，见 <<cli-args, CLI_ARGS>> 。

* 安装好最新的 NVIDIA 显卡驱动
** 必须要 2024 年三月以后的驱动才能支持 CUDA 12.4。
** 游戏驱动或 Studio 驱动均可。
** 只需要在宿主系统中安装驱动即可，容器中不需要再安装驱动。

* 安装好 Docker 或 Podman
** Linux 用户可能需要安装 https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html[NVIDIA Container Toolkit] 并进行初始化（使得容器可以访问宿主机的 GPU）。

** Windows 用户建议使用 https://www.docker.com/products/docker-desktop/[Docker Desktop] 并在安装时启用 WSL2，并 https://zhuanlan.zhihu.com/p/345645621[限制内存用量] 。

** Windows 用户也可使用
https://podman-desktop.io/[Podman Desktop]
，在安装时启用 WSL2，并在之后启用
https://podman-desktop.io/docs/podman/gpu[容器内 GPU 访问] 。


## 运行方法

* 以下命令均使用了一次性容器 (`--rm`) 来保持环境整洁、配置清晰。
* 不建议 WSL2 用户把文件存放在 NTFS 分区内，跨文件系统互访性能极低，且会权限混乱。
* 注意命令中的 `dockerproxy.cn` 为 Docker Hub 镜像站点地址。如果站点失效，可替换为备用地址，
https://www.coderjia.cn/archives/dba3f94c-a021-468a-8ac6-e840f85867ea[国内可用 Docker 镜像源汇总]
。

.使用 Docker
[source,sh]
----
mkdir -p storage

docker pull dockerproxy.cn/yanwk/comfyui-boot:cu124-cn

docker run -it --rm \
  --name comfyui-cn \
  --gpus all \
  -p 8188:8188 \
  -v "$(pwd)"/storage:/root \
  -e CLI_ARGS="--fast" \
  -e PIP_INDEX_URL="https://mirrors.cernet.edu.cn/pypi/web/simple" \
  -e HF_ENDPOINT="https://hf-mirror.com" \
  yanwk/comfyui-boot:cu124-cn
----

.使用 Podman
[source,sh]
----
mkdir -p storage

podman pull dockerproxy.cn/yanwk/comfyui-boot:cu124-cn

podman run -it --rm \
  --name comfyui-cn \
  --device nvidia.com/gpu=all \
  --security-opt label=disable \
  --security-opt seccomp=unconfined \
  -p 8188:8188 \
  -v "$(pwd)"/storage:/root \
  -e CLI_ARGS="--fast" \
  -e PIP_INDEX_URL="https://mirrors.cernet.edu.cn/pypi/web/simple" \
  -e HF_ENDPOINT="https://hf-mirror.com" \
  yanwk/comfyui-boot:cu124-cn
----

容器启动后，启动脚本会自动开始下载，如果之前下载未完成，则会尝试继续下载。

待下载完毕、程序启动后：

1. 打开浏览器访问 http://localhost:8188/
2. 如界面为英文，刷新浏览器，或点击右侧菜单的“Switch Locale”切换语言（可能要点两遍）。
3. 点击右侧菜单的“加载”按钮，加载
https://gh-proxy.com/https://raw.githubusercontent.com/comfyanonymous/ComfyUI_examples/master/flux/flux_schnell_checkpoint_example.png[这张图片]
（该图内嵌 json，内含 FLUX.1 Schnell FP8 Checkpoint 工作流），再点击右侧菜单的“添加提示词队列”，即可运行工作流。


## 运行方法-不下载模型

如果启动时下载过于缓慢，可以改用最简启动：

.使用 Docker
[source,sh]
----
mkdir -p storage

docker pull dockerproxy.cn/yanwk/comfyui-boot:cu124-cn

docker run -it --rm \
  --name comfyui-cn \
  --gpus all \
  -p 8188:8188 \
  -v "$(pwd)"/storage:/root \
  -e CLI_ARGS="" \
  yanwk/comfyui-boot:cu124-cn \
  /bin/bash /runner-scripts/minimal-start.sh
----

.使用 Podman
[source,sh]
----
mkdir -p storage

podman pull dockerproxy.cn/yanwk/comfyui-boot:cu124-cn

podman run -it --rm \
  --name comfyui-cn \
  --device nvidia.com/gpu=all \
  --security-opt label=disable \
  --security-opt seccomp=unconfined \
  -p 8188:8188 \
  -v "$(pwd)"/storage:/root \
  -e CLI_ARGS="" \
  yanwk/comfyui-boot:cu124-cn \
  /bin/bash /runner-scripts/minimal-start.sh
----

执行 `minimal-start.sh` 只会下载 ComfyUI 与 Manager，不下载任何模型与扩展。


## 构建镜像-国内源

使用纯国内环境构建镜像，可以使用专门的 `Dockerfile-cn` 文件：

[source,sh]
----
docker pull docker.m.daocloud.io/opensuse/tumbleweed:latest

docker build . -t yanwk/comfyui-boot:cu124-cn -f Dockerfile-cn
----

`Dockerfile-cn` 中绝大部分文件从国内源下载， PyTorch 部分来自 download.pytorch.org ，目前该域名下载速度基本正常。

构建后，运行方法同上，略过 pull 步骤即可。


## 组件信息

* 基于 CUDA 12.4 的 PyTorch + xFormers 稳定版
* Python 开发包 (3.12)
* GCC C++ (13)
* OpenCV 开发包
* FFmpeg 与 x264、x265 编码器
* CMake, Ninja 等编译工具
* Vim, Fish, fd 等 CLI 工具
* 未包含 CUDA 开发包（以减小镜像体积）


## 使用到的国内源

各地网络情况不一，访问镜像站点有快有慢，可按需搜索替换。

* Docker Hub 镜像仓库
** dockerproxy.cn
** https://www.coderjia.cn/archives/dba3f94c-a021-468a-8ac6-e840f85867ea[国内可用 Docker 镜像源汇总]
** 替换为 `docker.io` 即为官方源地址

* PyPI
** https://mirrors.cernet.edu.cn/pypi/web/simple
** 可按需替换为阿里云源 http://mirrors.aliyun.com/pypi/simple/
** 替换启动参数（环境变量）即可

* HuggingFace
** https://hf-mirror.com

* GitHub
** https://gh-proxy.com

* openSUSE 与 PackMan
** https://mirror.nju.edu.cn/opensuse/tumbleweed/
** https://mirror.nju.edu.cn/packman/suse/openSUSE_Tumbleweed/Essentials/
** https://mirrors.cernet.edu.cn/opensuse/tumbleweed/
** https://mirrors.cernet.edu.cn/packman/suse/openSUSE_Tumbleweed/Essentials/


[[pre-start]]
## 预启动脚本

脚本执行顺序为： +
代理脚本 → 下载脚本（仅初次启动） → 普通预启动脚本 → 启动命令

### 关于挂代理
* 本镜像启动时不需要挂代理，理论上更新时也不需要，但是用户使用中可能遇到：
** 访问 GitHub（使用 Manager 下载新扩展）
** 访问 HuggingFace（一些扩展通过硬编码 URL 下载模型）
** 访问 Civitai（一些扩展将其作为画廊）
* 如何判断节点运行时卡下载：如果命令行输出有百分比进度，但 CPU、GPU 占用与硬盘读写均很低，则多半为卡下载。
* Docker Desktop 用户可在设置中找到“代理”（Settings - Resources - Proxies）选项页。
* Linux 用户可以用下述方法来配置代理：

### 网络代理脚本

创建该文件，它会在容器启动的第一时间运行： +
----
./storage/user-scripts/set-proxy.sh
----
（在容器第一次启动时，该文件也会被自动创建）

.参考脚本内容（点击展开）：
[%collapsible]
====
提示：在容器内，不能直接通过 127.0.0.1 访问宿主机，需要走（虚拟）局域网，而容器平台一般都贴心绑定好了宿主机的 IP 地址-主机名：

* 在 Docker 中是 `host.docker.internal`
* 在 Podman 中是 `host.containers.internal`

[source,sh]
----
#!/bin/bash
set -eu
export HTTP_PROXY=http://host.docker.internal:1081
export HTTPS_PROXY=$HTTP_PROXY
export http_proxy=$HTTP_PROXY
export https_proxy=$HTTP_PROXY
export NO_PROXY="localhost,*.local,*.internal,[::1],fd00::/7,
10.0.0.0/8,127.0.0.0/8,169.254.0.0/16,172.16.0.0/12,192.168.0.0/16,
10.*,127.*,169.254.*,172.16.*,172.17.*,172.18.*,172.19.*,172.20.*,
172.21.*,172.22.*,172.23.*,172.24.*,172.25.*,172.26.*,172.27.*,
172.28.*,172.29.*,172.30.*,172.31.*,172.32.*,192.168.*,
*.cn,ghproxy.com,*.ghproxy.com,ghproxy.org,*.ghproxy.org,
gh-proxy.com,*.gh-proxy.com,ghproxy.net,*.ghproxy.net"
export no_proxy=$NO_PROXY
echo "[INFO] 代理设置为 $HTTP_PROXY"
----
====


### 普通预启动脚本

如果需要在 ComfyUI 启动前执行一些操作，可以创建这个文件：
----
./storage/user-scripts/pre-start.sh
----


[[cli-args]]
## CLI_ARGS 参考

[cols="1,1"]
|===
|启动参数 |说明

|--lowvram
|如果显存只有 4G （程序启动时会检测显存，自动开启）

|--novram
|如果用了 __--lowvram__ 还是显存不够，直接改用 CPU 内存

|--cpu
|用 CPU 来跑，会很慢

|--use-pytorch-cross-attention
|如果不想用 xFormers，而改用 PyTorch 原生交叉注意力机制。在 WSL2 上可能会有更好的速度／显存占用表现，但在 Linux 宿主机上会明显更慢。

|--preview-method taesd
|使用基于 TAESD 的高质量实时预览。使用 Manager 会覆盖该参数（需在 Manager 界面中设置预览方式）。

|--front-end-version Comfy-Org/ComfyUI_frontend@latest
|使用最新版本的 ComfyUI 前端

|--fast
|使用实验性的高性能模式，对 40 系显卡 + CUDA 12.4 + 最新 PyTorch + fp8-e4m3fn 模型可达 40% 性能提升。但也有可能造成图像质量劣化。
https://github.com/comfyanonymous/ComfyUI/commit/9953f22fce0ba899da0676a0b374e5d1f72bf259[来源]
|===

更多启动参数见 ComfyUI 的
https://github.com/comfyanonymous/ComfyUI/blob/master/comfy/cli_args.py[cli_args.py]
。


[[env-vars]]
## 环境变量参考

[cols="2,2,3"]
|===
|变量名|参考值|备注

|HTTP_PROXY +
HTTPS_PROXY
|http://localhost:1081 +
http://localhost:1081
|设置 HTTP 代理。

|PIP_INDEX_URL
|'https://mirrors.cernet.edu.cn/pypi/web/simple'
|设置 PyPI 镜像站点。

|HF_ENDPOINT
|'https://hf-mirror.com'
|设置 HuggingFace 镜像站点。

|HF_TOKEN
|'hf_your_token'
|设置 HuggingFace
https://huggingface.co/settings/tokens[访问令牌]
（Access Token）。

|HF_HUB_ENABLE_HF_TRANSFER
|1
|启用 HuggingFace Hub 实验性高速传输，仅对 >1000Mbps 且十分稳定的连接有意义（比如云服务器）。
https://huggingface.co/docs/huggingface_hub/hf_transfer[文档]

|TORCH_CUDA_ARCH_LIST
|7.5 +
或 +
'5.2+PTX;6.0;6.1+PTX;7.5;8.0;8.6;8.9+PTX'
|设置 PyTorch 及扩展的编译目标，Linux 下一般无需手动指定。
如有必要，一般设置为自己的 GPU 架构版本。
https://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/[参考]

|CMAKE_ARGS
|'-DBUILD_opencv_world=ON -DWITH_CUDA=ON -DCUDA_FAST_MATH=ON -DWITH_CUBLAS=ON -DWITH_NVCUVID=ON'
|设置 CMAKE 编译参数，一般无需调整。

|===


## 声明

代码使用
link:../LICENSE[木兰公共许可证, 第2版] 。
中英双语哦！
