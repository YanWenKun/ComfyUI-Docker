# 用于 ComfyUI 的 Docker 镜像

中文 | ℹ️ *link:README.adoc[English]*

https://github.com/comfyanonymous/ComfyUI[ComfyUI]
是一套使用节点工作流的 Stable Diffusion 图形界面。 +
本仓库所构建的
https://hub.docker.com/r/yanwk/comfyui-boot[Docker 镜像]
包含其依赖项，及下载／启动脚本。

## 快速开始 - NVIDIA GPU

```sh
mkdir -p \
  storage \
  storage-models/models \
  storage-models/hf-hub \
  storage-models/torch-hub \
  storage-user/input \
  storage-user/output \
  storage-user/workflows

docker run -it --rm \
  --name comfyui \
  --runtime nvidia \
  --gpus all \
  -p 8188:8188 \
  -v "$(pwd)"/storage:/root \
  -v "$(pwd)"/storage-models/models:/root/ComfyUI/models \
  -v "$(pwd)"/storage-models/hf-hub:/root/.cache/huggingface/hub \
  -v "$(pwd)"/storage-models/torch-hub:/root/.cache/torch/hub \
  -v "$(pwd)"/storage-user/input:/root/ComfyUI/input \
  -v "$(pwd)"/storage-user/output:/root/ComfyUI/output \
  -v "$(pwd)"/storage-user/workflows:/root/ComfyUI/user/default/workflows \
  -e CLI_ARGS="--disable-xformers" \
  yanwk/comfyui-boot:cu128-slim
```


## CUDA 兼容性列表

[cols="1,1,1,1,1,1,1,1,1", options="header"]
|===
| GPU 架构 | Blackwell | Hopper | Ada Lovelace | Ampere | Turing | Volta | Pascal | Maxwell


| 示例GPU
| RTX 5090 | H100 | RTX 4090 | RTX 3090 
| RTX 2080 +
GTX 1660 
| TITAN V | GTX 1080 | GTX 980

| cu130
| ✔️ | ✔️ | ✔️ | ✔️ | ✔️ | ❌ | ❌ | ❌

| cu128 ⭐
| ✔️ | ✔️ | ✔️ | ✔️ | ✔️ | ✔️ | ❌ | ❌

| cu126
| ❌ | ✔️ | ✔️ | ✔️ | ✔️ | ✔️ | ✔️ | ✔️

|===

* **推荐 CUDA 12.8**，这也是 PyTorch 当前的
https://github.com/pytorch/pytorch/issues/159980[稳定版本]
。

* 如果你不清楚 GPU（如 Quadro、Tesla）是哪一代架构，参考
https://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/[这篇文章]
。

NOTE: __这些兼容性限制与 NVIDIA CUDA Toolkit 无直接关联，而是 PyTorch 官方为了避免二进制包过大而做出的取舍。可以参考其
https://github.com/pytorch/pytorch/releases/tag/v2.8.0[发布说明]
与
https://github.com/pytorch/pytorch/blob/main/.ci/manywheel/build_cuda.sh[编译脚本]
。__


## CUDA 镜像标签

### Slim

`slim` 镜像仅预装基本的 ComfyUI 与 Manager，同时预装大量依赖项，方便后续无痛安装热门自定义节点（扩展插件）。推荐初学者使用。

* link:cu126-slim/README.adoc[`cu126-slim`]
** CUDA 12.6, Python 3.12

* link:cu128-slim/README.adoc[`cu128-slim`] ⭐
** CUDA 12.8, Python 3.12

* link:cu130-slim/README.adoc[`cu130-slim`]
** CUDA 13.0, Python 3.13 (GIL 版本), 无 xFormers

### MEGAPAK

`megapak` 镜像为整合包，包含开发套件与常用自定义节点（扩展插件）。

* link:cu126-megapak/README.adoc[`cu126-megapak`]
** CUDA 12.6, Python 3.12, GCC 13

* link:cu128-megapak/README.adoc[`cu128-megapak`]
** CUDA 12.8, Python 3.12, GCC 14

### 测试镜像

* link:nightly/README.adoc[`nightly`]
** 使用最新开发预览版的 PyTorch


## 更多镜像标签

* link:rocm/README.zh.adoc[`rocm`]

** 适用于 AMD GPU，使用最新的 ROCm 7

* link:rocm6/README.zh.adoc[`rocm6`]

** 适用于 AMD GPU，使用稳定的 ROCm 6

* link:xpu-cn/[`xpu-cn`]

** 适用于 Intel GPU
** 针对国内网络环境重写，尽量使用镜像源，减少代理需求

* link:cpu/[`cpu`]

** 仅适用于 CPU，镜像体积较小

* link:archived/[archived]

** 已退役的旧版本镜像


## 声明

代码使用
link:LICENSE[木兰公共许可证, 第2版] 。
中英双语哦！
